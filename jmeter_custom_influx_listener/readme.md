# Общее описание

В качестве альтернативы стандартному Jmeter InfluxdbBackendListenerClient ([ссылка на оф документацию](https://jmeter.apache.org/usermanual/component_reference.html#Backend_Listener)) можно использовать кастомное решение.

### Основные отличия:

1. Отсутствие группировки запросов (1 request из Jmeter = 1 точке в БД influx). Это позволяет добиться более высокой точности получаемой статистики, однако существенно увеличивает требования к генератору нагрузки в случае высокой интенсивности запросов. Данный listener годится только для сценариев/тест планов со сравнительно низкой нагрузкой (не более 100 запросов в секунду).
1. Возможность логировать запросы в текстовый файл. Каждый запрос пишется сразу в готовом для отправки в influx виде ([описание стандартной структуры запроса](https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_reference/)). Возможны ситуации, когда БД influx оказывается недоступна во время теста с одного из генераторов нагрузки (либо недоступна вовсе). И в некоторых из подобных случаев проще передать файл с готовым логом запросов за весь прошедший тест на машину с установленным influx, чем возиться с доступами напрямую.
1. Точки (информация о каждом реквесте) отправляются в influx (либо пишутся в файл) пачками по 500 штук в одном запросе. Если скрипт прервать аварийно - последние точки, объединенные в одну пачку, отправлены не будут.

Файл необходимо добавить в Jmeter в качестве плагина: ...\apache-jmeter-5.x.x\lib\ext\influx_listener_plugin.jar

Для использования нужно добавить в тест-план "Backend Listener", у которого в поле "implementation" выбрать "NTInfluxBackendListener".

---
#### Параметры:

1. influxHost - хост в форме http://[host address or name]:[port]
1. influxDataBase - имя базы данных influx.
1. influxMeasurement - имя influx measurement (измерения в базе данных influx)
1. currentNodeName - имя генератора нагрузки. Неизменяемо
1. currentApplication - имя приложения, с которого подается нагрузка
1. filter_regular_expression - фильтр в виде регулярного выражения. Будут записаны/отправлены только те запросы, которые соответствуют этому выражению
1. outFilePath - абсолютный путь к файлу, в который будут записаны точки в виде лога запросов. Опциональное поле. Необходимо заполнить только если listener запущен в режиме записи в файл. Путь может содержать несуществующие директории - они будут созданы в момент запуска скрипта
1. description - неизменяемое поле. Содержит укороченное описание работы флага следующего параметра
1. where_to_write_flag - флаг, определяющий режим работы листенера. Должно стоять число от 1 до 3. 1 - запись всех точек только в файл в виде лога. 2 - отправка всех точек в influx. 3 - запись точек в файл и отправка в influx одновременно. Если в этом поле стоит флаг 1, то при работе скрипта параметры influxHost и influxDataBase не учитываются.
1. tag_customTagName/field_customFieldName - кастомные тэги и поля могут быть добавлены в каждый запрос, отправляемый в influx. Для этого необходимо добавить параметр (или параметры) в listener с помощью "Add", а в названии нового параметра указать префикс tag_[имя параметра] - для тегов или field_[имя параметра] - для полей. При этом важно помнить, что значения этих параметров должны быть статичными (как user defined vars).
> На сайте оф документации influx можно найти, что такое tags и fields с точки зрения influx. Это важно для понимания, какой вид параметра нужно добавить в той или иной ситуации.

---
### Обработка логов

После завершения теста с использованием NTInfluxBackendListener в режиме логирования запросов (точек) в папке логов (параметр outFilePath) можно будет найти несколько файлов (по числу запущенных потоков) в формате .csv - это и есть логи. В случае, если этих точек 10-ки или 100-ни тысяч - их дальнейшая переправка в influx может оказаться довольно трудоемкой. Для облегчения задачи можно использовать готовый вспомогательный скрипт: внизу страницы.

Это обычный скрипт jmeter, который берет все файлы формата ".csv" из указанной директории, парсит, разделяет на небольшие пачки и отправляет их по одной в influx. Скрипт должен быть запущен в один поток в одну итерацию (со всем остальным справятся циклы внутри него). Размер и количество файлов не имеет значения. Все строки будут обработаны, пустые - будут пропущены.
> Важно: 1 строка = 1 точка и каждая точка должна быть в [формате стандартного запроса в influx](https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_reference/).

Вначале скрипт находит все файлы подходящего формата, затем начинает их обрабатывать по одному. Каждый файл он делит на части - по количеству точек (=строк), которые будут отправлены в body одного запроса (по умолчанию - 100). Пустые строки не учитываются.

Перед запуском скрипта необходимо настроить параметры внутри vars general:

1. influx_files_data_path - это путь к директории со всеми файлами логов для influx, которые необходимо отправить. Абсолютный.
1. point_rows - количество точек, которые будут отправляться в каждом request после парсинга. Значение можно оставить по умолчанию, данный размер группировки позволяет достаточно быстро обрабатывать даже крупные файлы. Но можно и увеличить. При этом ставить значение более 1000 не рекомендуется, есть риск, что не справится либо скрипт, либо influx.
1. host, port - имя хоста и порта машины, на которой размещен influx
1. influxDB_name - имя базы данных influx, в которую необходимо провести запись точек из файлов логов.

---
### Описание созданных полей

По итогу работы плагина в базе данных influx будет создано измерение (measurement) с полями:
- timestamp (primary key in nanosec) - таймстамп момента окончания транзакции в милисекундах;
- node (tag value) - имя генератора подачи нагрузки;
- application (tag value) - имя приложения подачи нагрузки;
- thread (tag value) - имя потока = имя thread_group + номер потока.
- transaction (tag value) - имя транзакции (операции)
- status (tag value) - статус "pass/fail"
- value (field value) - время выполения транзакции (операции) в милисекундах

Опциональные поля, могут быть пусты для сэмплеров, которые не являются request запросами:
- response_code (tag value) - код ответа
- response_headers (tag value) - хэдеры ответа
- response_data (tag value) - тело ответа
- response_message (tag value) - сообщение из sampler. Обычно либо "OK", либо сообщение об ошибке.
- request_data (tag value) - полная инфа из сэмплера: groovy code, url, body, cookies и тд
- request_headers (tag value) - хэдеры запроса
- request_url (tag value) - url адрес запроса

---
### Файлы

Плагин: influx_listener_plugin.jar

Вспомогательный скрипт отправки логов в influx: send_influx_info.jmx

Пример дашборда для Grafana: dash.json
