__Общее описание__

В качестве альтернативы стандартному Jmeter InfluxdbBackendListenerClient (ссылка на оф документацию) можно использовать кастомное решение.

Основные отличия:

1. Отсутствие группировки запросов (1 request из Jmeter = 1 точке в БД influx). Это позволяет добиться более высокой точности получаемой статистики, однако существенно увеличивает требования к генератору нагрузки в случае высокой интенсивности запросов. Данный listener годится только для сценариев/тест планов со сравнительно низкой нагрузкой (не более 100 запросов в секунду).
1. Возможность логировать запросы в текстовый файл. Каждый запрос пишется сразу в готовом для отправки в influx виде (описание стандартной структуры запроса). Возможны ситуации, когда БД influx оказывается недоступна во время теста с одного из генераторов нагрузки (либо недоступна вовсе). И в некоторых из подобных случаев проще передать файл с готовым логом запросов за весь прошедший тест на машину с установленным influx, чем возиться с доступами напрямую.
1. Точки (информация о каждом реквесте) отправляются в influx (либо пишутся в файл) пачками по 500 штук в одном запросе. Если скрипт прервать аварийно - последние точки, объединенные в одну пачку, отправлены не будут.

Скачать: influx_listener_plugin.jar

Файл необходимо добавить в Jmeter в качестве плагина: ...\apache-jmeter-5.x.x\lib\ext\influx_listener_plugin.jar

Для использования нужно добавить в тест-план "Backend Listener", у которого в поле "implementation" выбрать "NTInfluxBackendListener".

Параметры:

1. influxHost - хост в форме http://[host address or name]:[port]
1. influxDataBase - имя базы данных influx.
1. influxMeasurement - имя influx measurement (измерения в базе данных influx)
1. currentNodeName - имя генератора нагрузки. Неизменяемо
1. currentApplication - имя приложения, с которого подается нагрузка
1. filter_regular_expression - фильтр в виде регулярного выражения. Будут записаны/отправлены только те запросы, которые соответствуют этому выражению
1. outFilePath - абсолютный путь к файлу, в который будут записаны точки в виде лога запросов. Опциональное поле. Необходимо заполнить только если listener запущен в режиме записи в файл. Путь может содержать несуществующие директории - они будут созданы в момент запуска скрипта
1. description - неизменяемое поле. Содержит укороченное описание работы флага следующего параметра
1. where_to_write_flag - флаг, определяющий режим работы листенера. Должно стоять число от 1 до 3. 1 - запись всех точек только в файл в виде лога. 2 - отправка всех точек в influx. 3 - запись точек в файл и отправка в influx одновременно. Если в этом поле стоит флаг 1, то при работе скрипта параметры influxHost и influxDataBase не учитываются.
1. tag_customTagName/field_customFieldName - кастомные тэги и поля могут быть добавлены в каждый запрос, отправляемый в influx. Для этого необходимо добавить параметр (или параметры) в listener с помощью "Add", а в названии нового параметра указать префикс tag_[имя параметра] - для тегов или field_[имя параметра] - для полей. При этом важно помнить, что значения этих параметров должны быть статичными (как user defined vars). На сайте оф документации influx можно найти, что такое tags и fields с точки зрения influx. Это важно для понимания, какой вид параметра нужно добавить в той или иной ситуации.

--------------------------------------------------

После завершения теста с использованием NTInfluxBackendListener в режиме логирования запросов (точек) в папке логов (параметр outFilePath) можно будет найти несколько файлов (по числу запущенных потоков) в формате .csv - это и есть логи. В случае, если этих точек 10-ки или 100-ни тысяч - их дальнейшая переправка в influx может оказаться довольно трудоемкой. Для облегчения задачи можно использовать готовый вспомогательный скрипт: вот такой.

Это обычный скрипт jmeter, который берет все файлы формата ".csv" из указанной директории, парсит, разделяет на небольшие пачки и отправляет их по одной в influx. Скрипт должен быть запущен в один поток в одну итерацию (со всем остальным справятся циклы внутри него). Размер и количество файлов не имеет значения. Все строки будут обработаны, пустые - будут пропущены. Важно: 1 строка = 1 точка и каждая точка должна быть в формате стандартного запроса в influx.

Вначале скрипт находит все файлы подходящего формата, затем начинает их обрабатывать по одному. Каждый файл он делит на части - по количеству точек (=строк), которые будут отправлены в body одного запроса (по умолчанию - 100). Пустые строки не учитываются.

Перед запуском скрипта необходимо настроить параметры внутри vars general:

1. influx_files_data_path - это путь к директории со всеми файлами логов для influx, которые необходимо отправить. Абсолютный.
1. point_rows - количество точек, которые будут отправляться в каждом request после парсинга. Значение можно оставить по умолчанию, данный размер группировки позволяет достаточно быстро обрабатывать даже крупные файлы. Но можно и увеличить. При этом ставить значение более 1000 не рекомендуется, есть риск, что не справится либо скрипт, либо influx.
1. host, port - имя хоста и порта машины, на которой размещен influx
1. influxDB_name - имя базы данных influx, в которую необходимо провести запись точек из файлов логов.

--------------------------------------------------

По итогу работы плагина в базе данных influx будет создано измерение (measurement) с полями:

primary key in nanosec	tag value	tag value	tag value	tag value	tag value	tag value	tag value	tag value	tag value	tag value	tag value	tag value	field value
таймстамп момента
окончания транзакции
в милисекундах

имя генератора
подачи нагрузки

имя приложения
подачи нагрузки

имя потока - имя thread_group + номер потока.	имя транзакции
(операции)	статус
"pass/fail"	код ответа	хэдеры ответа	тело ответа	сообщение из sampler. Обычно либо "OK", либо сообщение об ошибке.	Полная инфо из сэмплера: groovy code, url, body, cookies и тд	хэдеры запроса	url адрес запроса	время выполения
транзакции (операции)
в милисекундах
Поля:

response_code
response_headers
response_data
response_message

request_data
request_headers
request_url

 - опциональны. Могут быть пусты для сэмплеров, которые не являются request запросами.



Пример дашборда
